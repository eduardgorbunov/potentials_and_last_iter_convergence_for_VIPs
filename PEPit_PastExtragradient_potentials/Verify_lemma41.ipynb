{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e5e7326-01c2-43ad-9b0a-d55f38f68342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pepit==0.0.2 in /home/ataylor/anaconda3/lib/python3.9/site-packages (0.0.2)\n",
      "Requirement already satisfied: cvxpy>=1.1.17 in /home/ataylor/anaconda3/lib/python3.9/site-packages (from pepit==0.0.2) (1.2.0)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /home/ataylor/anaconda3/lib/python3.9/site-packages (from cvxpy>=1.1.17->pepit==0.0.2) (0.6.2.post5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/ataylor/anaconda3/lib/python3.9/site-packages (from cvxpy>=1.1.17->pepit==0.0.2) (1.7.1)\n",
      "Requirement already satisfied: ecos>=2 in /home/ataylor/anaconda3/lib/python3.9/site-packages (from cvxpy>=1.1.17->pepit==0.0.2) (2.0.10)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ataylor/anaconda3/lib/python3.9/site-packages (from cvxpy>=1.1.17->pepit==0.0.2) (1.20.3)\n",
      "Requirement already satisfied: scs>=1.1.6 in /home/ataylor/anaconda3/lib/python3.9/site-packages (from cvxpy>=1.1.17->pepit==0.0.2) (3.2.0)\n",
      "Requirement already satisfied: qdldl in /home/ataylor/anaconda3/lib/python3.9/site-packages (from osqp>=0.4.1->cvxpy>=1.1.17->pepit==0.0.2) (0.1.5.post0)\n"
     ]
    }
   ],
   "source": [
    "# If PEPit is not installed yet, you can run this cell.\n",
    "!pip install pepit==0.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bff8d9-bbbf-4fcc-b206-ecd9517cad75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Code description\n",
    "This code aims at verifying (numerically) the inequality from Lemma 4.1 of the paper\n",
    "> \"Last-Iterate Convergence of Optimistic Gradient Method for Monotone\n",
    "       Variationnal Inequalities\".\n",
    "\n",
    "## Problem setup:\n",
    "Consider the problem of finding a zero of a monotone Lipschitz operator:\n",
    "       $$ \\text{find } x\\in Q \\text{ such that } \\langle F(x);y-x\\rangle \\geq 0 \\text{ for all }y\\in Q$$\n",
    "where $F$ is monotone and $L$-Lipschitz, and $Q$ is convex and compact.\n",
    "\n",
    "## Algorithm: \n",
    "The past extragradient method is described by two sets of iterates:\n",
    "$x^k$, $\\tilde{x}^k$ where $k$ denotes the iteration counter, as follows:\n",
    "\n",
    "- Initialize $\\tilde{x}^0 = x^0$, and $x^1=\\mathrm{Proj}_Q(x^0 - \\gamma  F(x^0))$, then run\n",
    "- for $k=1,...,N-1$:\n",
    "     $$\\tilde{x}^k    = \\mathrm{Proj}_Q(x^k - \\gamma  F(\\tilde{x}^{k-1}))$$\n",
    "     $$ x^{k+1} = \\mathrm{Proj}_Q(x^k - \\gamma  F(\\tilde{x}^k))$$\n",
    "\n",
    "## Potential function:\n",
    "Denotes $p_k := \\|x^k - x^{k-1}\\|^2+ \\| x^k - x^{k-1} - 2 \\gamma (F(x^k) - F(\\tilde{x}^{k-1})) \\|^2$ the code compute the maximum (i.e., worst-case) value of\n",
    " $$ p_{k+1} - p_k + (1-5 L^2 \\gamma^2) \\|x^{k+1}-\\tilde{x}^k\\|^2 + \\gamma^2 \\|F(x^{k+1})-F(\\tilde{x}^k)\\|^2,$$\n",
    "which should always be \"$\\cdot\\leq 0$\" for verifying the identity from Lemma 4.1. In the code below, we use k = 1 for notational convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8958e26-c710-4a7b-af9d-541254ed906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code before executing the cell below\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from PEPit import PEP\n",
    "from PEPit.operators import LipschitzStronglyMonotoneOperator\n",
    "from PEPit.functions import ConvexIndicatorFunction\n",
    "from PEPit.primitive_steps import proximal_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac118630-e97f-4940-86d0-b21fcb0fa237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did PEPit verify the potential (within prescribed numerical precision)? True  \t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8230715543031693e-09"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################\n",
    "# parameters: MODIFY HERE!\n",
    "\n",
    "# pick the parameters for which you want to verify\n",
    "# the inequality (numerically)\n",
    "L = 1;\n",
    "gamma = 10;\n",
    "\n",
    "##########################################################\n",
    "\n",
    "# verbose & verification tolerance options\n",
    "verbose = 0;\n",
    "tolerance = 1e-5;\n",
    "\n",
    "# (0) Initialize an empty PEP\n",
    "problem = PEP()\n",
    "\n",
    "# (1) Set up the problem class\n",
    "L  =  L; mu = 0; # F is 1-Lipschitz and 0-strongly monotone\n",
    "F    = problem.declare_function(LipschitzStronglyMonotoneOperator, param={'L': L, 'mu': mu})\n",
    "indQ = problem.declare_function(ConvexIndicatorFunction, param={'D': np.inf})\n",
    "\n",
    "# (2) Set up the starting points\n",
    "tx0 = problem.set_initial_point() # this is \\tilde{x}^0\n",
    "x0  = problem.set_initial_point() # this is x^0\n",
    "\n",
    "# (3) Run the algorithm\n",
    "x1,_,_       = proximal_step(x0 - gamma * F.gradient(tx0),indQ,1);\n",
    "tx1,_,_      = proximal_step(x1 - gamma * F.gradient(tx0),indQ,1); \n",
    "x2,_,_       = proximal_step(x1 - gamma * F.gradient(tx1),indQ,1);\n",
    "\n",
    "#  define the expressions (recall that our objective is to verify that\n",
    "#  p2 - p1 + residual<=0 for all F and sequence generated by the\n",
    "#  past extragradient method.\n",
    "p1 = (x1-x0)**2 + (x1-x0-2*gamma*(F.gradient(x1)-F.gradient(tx0)))**2;\n",
    "p2 = (x2-x1)**2 + (x2-x1-2*gamma*(F.gradient(x2)-F.gradient(tx1)))**2;\n",
    "residual = (1-5*L**2*gamma**2)*(x2-tx1)**2 + gamma**2 * (F.gradient(x2)-F.gradient(tx1))**2;\n",
    "\n",
    "# (4) Set up the performance measure \n",
    "expression_to_verify = p2 - p1 + residual;\n",
    "problem.set_performance_metric(expression_to_verify);\n",
    "\n",
    "# (5) Solve the PEP\n",
    "worstcase_value = problem.solve(verbose=verbose)\n",
    "\n",
    "\n",
    "# (6) is the potential verified? Success if expression2 - expression1 <= 0 for the \n",
    "#     choice of the parameters above.\n",
    "print('Did PEPit verify the potential (within prescribed numerical precision)? {:}  \\t'.format(worstcase_value<tolerance))\n",
    "worstcase_value # this should be close to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e563ff-8690-4b29-95bf-e989154d6fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
